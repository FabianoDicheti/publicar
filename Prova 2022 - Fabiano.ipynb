{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f197c49",
   "metadata": {},
   "source": [
    "## Prova Inteligencia Computacional - 2022\n",
    "## Fabiano Dicheti\n",
    "\n",
    "## _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b92d27",
   "metadata": {},
   "source": [
    "## Exercício 1) Escolha uma base de dados rotulada (com apenas variáveis numéricas, por exemplo, a base de dados IRIS) e faça o que se pede:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e041c9",
   "metadata": {},
   "source": [
    "Importar as bibiliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2376dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf5092",
   "metadata": {},
   "source": [
    "### a) Dividir aleatoriamente a base de dados, deixando 70% dos dados no conjunto de treinamento e os 30% restantes no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63df4a6",
   "metadata": {},
   "source": [
    "Para dividir aleatoriamente a base de dados IRIS em conjuntos de treinamento e teste, pode de usar a função train_test_split do módulo sklearn.model_selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd82995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a base de dados IRIS\n",
    "iris_dataset = load_iris()\n",
    "X = iris_dataset['data']\n",
    "y = iris_dataset['target']\n",
    "\n",
    "# Dividir a base de dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a6ea8",
   "metadata": {},
   "source": [
    "Aqui, X e y são os dados de entrada e alvos, respectivamente. X_train e y_train são os dados de treinamento e X_test e y_test são os dados de teste. O argumento test_size especifica a porcentagem de dados que serão incluídos no conjunto de teste.\n",
    "\n",
    "Neste caso, estamos usando 30% dos dados para o conjunto de teste e, portanto, 70% dos dados para o conjunto de treinamento. \n",
    "\n",
    "O argumento random_state garante que os dados são divididos da mesma maneira cada vez que o código é executado.\n",
    "\n",
    "É importante notar que essa divisão aleatória dos dados em conjuntos de treinamento e teste, permite avaliar o desempenho do modelo em dados que ele não viu durante o treinamento, o que é essencial para garantir que o modelo não está apenas \"memorizando\" os dados de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5e45f",
   "metadata": {},
   "source": [
    "### b) Normalizar os dados (usar média e desvio padrão dos dados de treinamento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b452a",
   "metadata": {},
   "source": [
    "Para normalizar os dados, pode-se usar a classe StandardScaler do módulo sklearn.preprocessing. Essa classe transforma os dados de modo que a média seja zero e o desvio padrão seja 1. \n",
    "\n",
    "Isso é útil para alguns algoritmos de aprendizado de máquina, pois pode ajudar a melhorar o desempenho e acelerar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "663dbc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um objeto StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustando o scaler com os dados de treinamento\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transformando os dados de treinamento e teste usando o scaler ajustado\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd04c3",
   "metadata": {},
   "source": [
    "Aqui, X_train e X_test são os dados de entrada de treinamento e teste, respectivamente. X_train_scaled e X_test_scaled são os dados normalizados de treinamento e teste, respectivamente.\n",
    "\n",
    "É importante notar que, quando se está trabalhando com conjuntos de dados que foram divididos em conjuntos de treinamento e teste, é importante ajustar o scaler com os dados de treinamento e, em seguida, usá-lo para transformar tanto os dados de treinamento quanto os dados de teste.\n",
    "\n",
    "Isso garante que o scaler não \"veja\" os dados de teste durante o ajuste, o que poderia levar a resultados enganosos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cfeae6",
   "metadata": {},
   "source": [
    "### c) Obter um modelo de classificação por meio de uma Rede Neural de Múltiplas Camadas – MLP, identificando os hiperpâmetros utilizados no treinamento da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3af2e",
   "metadata": {},
   "source": [
    "Para obter um modelo de classificação por meio de uma Rede Neural de Múltiplas Camadas (MLP), pode-se usar a classe MLPClassifier do módulo sklearn.neural_network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "404ce971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.37323752\n",
      "Iteration 2, loss = 1.19920884\n",
      "Iteration 3, loss = 1.01563886\n",
      "Iteration 4, loss = 0.85312679\n",
      "Iteration 5, loss = 0.72054455\n",
      "Iteration 6, loss = 0.61235139\n",
      "Iteration 7, loss = 0.52656180\n",
      "Iteration 8, loss = 0.45868941\n",
      "Iteration 9, loss = 0.40369211\n",
      "Iteration 10, loss = 0.36166158\n",
      "Iteration 11, loss = 0.33022449\n",
      "Iteration 12, loss = 0.30657729\n",
      "Iteration 13, loss = 0.28790698\n",
      "Iteration 14, loss = 0.27216485\n",
      "Iteration 15, loss = 0.25787624\n",
      "Iteration 16, loss = 0.24447849\n",
      "Iteration 17, loss = 0.23173122\n",
      "Iteration 18, loss = 0.21945535\n",
      "Iteration 19, loss = 0.20762005\n",
      "Iteration 20, loss = 0.19624955\n",
      "Iteration 21, loss = 0.18529727\n",
      "Iteration 22, loss = 0.17480907\n",
      "Iteration 23, loss = 0.16480602\n",
      "Iteration 24, loss = 0.15534221\n",
      "Iteration 25, loss = 0.14651788\n",
      "Iteration 26, loss = 0.13841387\n",
      "Iteration 27, loss = 0.13107354\n",
      "Iteration 28, loss = 0.12449969\n",
      "Iteration 29, loss = 0.11869145\n",
      "Iteration 30, loss = 0.11356781\n",
      "Iteration 31, loss = 0.10906278\n",
      "Iteration 32, loss = 0.10511290\n",
      "Iteration 33, loss = 0.10164210\n",
      "Iteration 34, loss = 0.09862245\n",
      "Iteration 35, loss = 0.09591698\n",
      "Iteration 36, loss = 0.09346925\n",
      "Iteration 37, loss = 0.09123646\n",
      "Iteration 38, loss = 0.08917140\n",
      "Iteration 39, loss = 0.08724276\n",
      "Iteration 40, loss = 0.08542256\n",
      "Iteration 41, loss = 0.08371118\n",
      "Iteration 42, loss = 0.08210498\n",
      "Iteration 43, loss = 0.08060014\n",
      "Iteration 44, loss = 0.07919427\n",
      "Iteration 45, loss = 0.07788697\n",
      "Iteration 46, loss = 0.07667778\n",
      "Iteration 47, loss = 0.07556259\n",
      "Iteration 48, loss = 0.07453505\n",
      "Iteration 49, loss = 0.07358985\n",
      "Iteration 50, loss = 0.07272157\n",
      "Iteration 51, loss = 0.07192426\n",
      "Iteration 52, loss = 0.07119218\n",
      "Iteration 53, loss = 0.07051832\n",
      "Iteration 54, loss = 0.06989604\n",
      "Iteration 55, loss = 0.06931911\n",
      "Iteration 56, loss = 0.06878240\n",
      "Iteration 57, loss = 0.06828068\n",
      "Iteration 58, loss = 0.06780955\n",
      "Iteration 59, loss = 0.06736528\n",
      "Iteration 60, loss = 0.06694485\n",
      "Iteration 61, loss = 0.06654543\n",
      "Iteration 62, loss = 0.06616493\n",
      "Iteration 63, loss = 0.06580174\n",
      "Iteration 64, loss = 0.06545456\n",
      "Iteration 65, loss = 0.06512238\n",
      "Iteration 66, loss = 0.06480437\n",
      "Iteration 67, loss = 0.06449986\n",
      "Iteration 68, loss = 0.06420803\n",
      "Iteration 69, loss = 0.06392858\n",
      "Iteration 70, loss = 0.06366084\n",
      "Iteration 71, loss = 0.06340443\n",
      "Iteration 72, loss = 0.06315906\n",
      "Iteration 73, loss = 0.06292349\n",
      "Iteration 74, loss = 0.06269713\n",
      "Iteration 75, loss = 0.06247937\n",
      "Iteration 76, loss = 0.06226966\n",
      "Iteration 77, loss = 0.06206747\n",
      "Iteration 78, loss = 0.06187224\n",
      "Iteration 79, loss = 0.06168355\n",
      "Iteration 80, loss = 0.06150099\n",
      "Iteration 81, loss = 0.06132419\n",
      "Iteration 82, loss = 0.06115277\n",
      "Iteration 83, loss = 0.06098643\n",
      "Iteration 84, loss = 0.06082493\n",
      "Iteration 85, loss = 0.06066815\n",
      "Iteration 86, loss = 0.06051575\n",
      "Iteration 87, loss = 0.06036754\n",
      "Iteration 88, loss = 0.06022331\n",
      "Iteration 89, loss = 0.06008293\n",
      "Iteration 90, loss = 0.05994610\n",
      "Iteration 91, loss = 0.05981281\n",
      "Iteration 92, loss = 0.05968292\n",
      "Iteration 93, loss = 0.05955629\n",
      "Iteration 94, loss = 0.05943277\n",
      "Iteration 95, loss = 0.05931231\n",
      "Iteration 96, loss = 0.05919474\n",
      "Iteration 97, loss = 0.05908030\n",
      "Iteration 98, loss = 0.05896863\n",
      "Iteration 99, loss = 0.05885952\n",
      "Iteration 100, loss = 0.05875289\n",
      "Iteration 101, loss = 0.05864850\n",
      "Iteration 102, loss = 0.05854619\n",
      "Iteration 103, loss = 0.05844603\n",
      "Iteration 104, loss = 0.05834789\n",
      "Iteration 105, loss = 0.05825174\n",
      "Iteration 106, loss = 0.05815748\n",
      "Iteration 107, loss = 0.05806524\n",
      "Iteration 108, loss = 0.05797511\n",
      "Iteration 109, loss = 0.05788672\n",
      "Iteration 110, loss = 0.05780000\n",
      "Iteration 111, loss = 0.05771489\n",
      "Iteration 112, loss = 0.05763136\n",
      "Iteration 113, loss = 0.05754934\n",
      "Iteration 114, loss = 0.05746878\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10,), learning_rate_init=0.1, max_iter=1000,\n",
       "              random_state=42, solver=&#x27;sgd&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(10,), learning_rate_init=0.1, max_iter=1000,\n",
       "              random_state=42, solver=&#x27;sgd&#x27;, verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10,), learning_rate_init=0.1, max_iter=1000,\n",
       "              random_state=42, solver='sgd', verbose=10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crindo o modelo\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, random_state=42,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "# Treinando o modelo\n",
    "mlp.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214af92d",
   "metadata": {},
   "source": [
    "Aqui, X_train_scaled e y_train são os dados de entrada e alvos de treinamento normalizados, respectivamente.\n",
    "\n",
    " - O argumento hidden_layer_sizes especifica o tamanho da camada escondida da MLP. O argumento max_iter especifica o número máximo de iterações do treinamento. \n",
    " - O argumento alpha especifica o valor de regularização. \n",
    " - O argumento solver especifica o algoritmo de otimização a ser usado.\n",
    " - O argumento verbose controla a quantidade de saída gerada durante o treinamento.\n",
    " - O argumento random_state controla a aleatoriedade do treinamento.\n",
    " - O argumento learning_rate_init especifica a taxa de aprendizado inicial.\n",
    "\n",
    "Esses são alguns dos hiperparâmetros que se pode ajustar para controlar o comportamento do modelo de MLP. Existem muitos outros hiperparâmetros disponíveis, como o número de camadas escondidas, o tamanho das camadas escondidas, o tipo de função de ativação e assim por diante. É importante experimentar diferentes valores para esses hiperparâmetros e encontrar os valores que dão os melhores resultados para o seu conjunto de dados específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72c074",
   "metadata": {},
   "source": [
    "### d) Escolher uma métrica para avaliação do modelo obtido em b) no conjunto de teste, apresentando e discutindo o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f4b4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo as predicoes\n",
    "y_pred = mlp.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25357ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusao\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0, 13,  0],\n",
       "       [ 0,  0, 13]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo a matriz de confusao\n",
    "print('Matriz de Confusao')\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b78dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracia: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Acuracia da predicao\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracia:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfcbd1e",
   "metadata": {},
   "source": [
    "Uma acurácia de 100% significa que todas as previsões feitas pelo modelo de Rede Neural de Múltiplas Camadas (MLP) foram corretas. Isso pode parecer excelente à primeira vista, mas é importante lembrar que uma acurácia de 100% nem sempre é um sinal de que o modelo está funcionando bem.\n",
    "\n",
    "Em alguns casos, uma acurácia de 100% pode ser um sinal de que o modelo está tendo um \"desempenho perfeito\", ou seja, que está realmente aprendendo as características do conjunto de dados e fazendo previsões precisas. No entanto, é importante lembrar que os modelos de aprendizado de máquina nem sempre são capazes de atingir esse nível de desempenho, e é mais comum que os modelos tenham uma acurácia um pouco menor.\n",
    "\n",
    "Em outros casos, uma acurácia de 100% pode ser um sinal de que o modelo está \"memorizando\" os dados de treinamento, o que significa que ele está apenas reproduzindo os rótulos dos exemplos de treinamento sem realmente aprender as características subjacentes do conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a6a07",
   "metadata": {},
   "source": [
    "## Exercício 2) Escolha uma base de dados rotulada (de imagens, por exemplo, MNIST) e faça o que se pede:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2be32c",
   "metadata": {},
   "source": [
    "Importar as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65950a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 19:12:42.262617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 19:12:42.335574: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd991c",
   "metadata": {},
   "source": [
    "### a) Dividir a base de dados em conjuntos de treinamento e teste e normalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f5d73e",
   "metadata": {},
   "source": [
    " - 1 - Carregar a base de dados Fashion MNIST e divida-a em conjuntos de treinamento e teste.\n",
    " - 2 - Pré-processamento dos dados:\n",
    " - 3 - Normalizar os pixels da imagem para que estejam entre 0 e 1.\n",
    " - 4 Transforar os rótulos em vetores de categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49700b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download da base de dados Fashion MNIST\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalizando as imagens\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13792570",
   "metadata": {},
   "source": [
    "### b) Obter um modelo de classificação por meio de uma Rede Neural Convolucional - CNN, identificando os hiperpâmetros utilizados no treinamento da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e718e4",
   "metadata": {},
   "source": [
    "###                                                               NOTA IMPORTANTE:\n",
    "\n",
    "####                      nao separar a arquitetura, a compilacao e o treinamento em celulas diferentes!!!\n",
    "####                      caso isso ocorra nao roda na GPU e trava tudo.\n",
    "####                      outra coisa importante: mesmo depois do treinamento a memoria da GPU fica presa (tem que reiniciar o kernel manualmente para usar para outras coisas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb716e84",
   "metadata": {},
   "source": [
    "Os hiperparâmetros são configurações que podem ser ajustadas em um modelo de aprendizado de máquina para melhorar o desempenho. \n",
    "\n",
    " - (3, 3): é o tamanho do kernel (filtro) da camada de convulsão.\n",
    "O kernel é aplicado a cada janela de pixels da imagem de entrada e produz uma saída que é uma combinação desses pixels. Quanto maior o kernel, mais informação é capturada, mas também haverá mais parâmetros para o modelo aprender e o tempo de treinamento pode aumentar.\n",
    "\n",
    " - 32: é o número de filtros na camada de convulsão. Cada filtro é treinado para detectar uma característica específica na imagem. \n",
    " Quanto maior o número de filtros, mais características podem ser detectadas, mas também haverá mais parâmetros para o modelo aprender e o tempo de treinamento pode aumentar.\n",
    " \n",
    " - (2, 2): Este é o tamanho da janela de pooling na camada de pooling.\n",
    " A camada de pooling é usada para reduzir a dimensão da imagem de entrada e também para suavizar as características detectadas pela camada de convulsão. O pooling é realizado aplicando uma operação (como a máxima ou a média) em uma janela de pixels e produzindo uma saída que é uma combinação desses pixels. Quanto maior o tamanho da janela de pooling, mais informação é perdida, mas também haverá menos parâmetros para o modelo aprender e o tempo de treinamento pode diminuir.\n",
    "\n",
    " - 'adam': otimizador usado para treinar o modelo.\n",
    " O otimizador controla o processo de aprendizado do modelo, atualizando os pesos das conexões entre as camadas de acordo com o gradiente da função de perda. O Adam é um otimizador popular que funciona bem em muitos problemas e é uma opção comum para modelos de redes neurais. Existem muitos outros otimizadores disponíveis, como o Stochastic Gradient Descent (SGD) e o Adagrad.\n",
    " \n",
    " - 'categorical_crossentropy': é a função de perda usada para medir o erro do modelo durante o treinamento.\n",
    " A função de perda é usada para minimizar o erro entre as previsões do modelo e os rótulos verdadeiros. A categorical_crossentropy é usada quando os rótulos são vetores de categoria (como os gerados pelo to_categorical neste exemplo).\n",
    " \n",
    " - 'accuracy': Este é o métrico usado para avaliar o desempenho do modelo durante o treinamento e durante a avaliação.\n",
    " A acurácia é a proporção de previsões corretas do modelo em relação ao total de previsões. \n",
    " \n",
    " - 50: número de épocas usado para treinar o modelo. Uma época é uma iteração completa através do conjunto de treinamento.\n",
    "\n",
    "\n",
    " - 'relu': A função ReLU (Rectified Linear Unit) é uma das funções de ativação mais populares e é comumente usada em camadas ftotalmente conectadas e em camadas de convulsão.\n",
    " A função ReLU é definida como relu(x) = max(0, x). Isso significa que todos os valores negativos são substituídos por 0 e todos os valores positivos são mantidos inalterados.\n",
    " \n",
    " - 'softmax': A função softmax é usada como função de ativação na camada de saída quando o modelo está sendo treinado para classificação em múltiplas classes.\n",
    " A função softmax é definida como softmax(x) = e^x / sum(e^x), onde sum(e^x) é a soma de todos os elementos de e^x. A saída da função softmax é uma distribuição de probabilidade sobre as classes, ou seja, cada elemento representa a probabilidade de que a entrada pertença a uma determinada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5d3efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,354\n",
      "Trainable params: 65,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 19:12:48.833517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:48.836803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:48.836944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:48.837960: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 19:12:48.839941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:48.840187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:48.840551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:49.171043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:49.171155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:49.171222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 19:12:49.171291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5657 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 19:12:50.310721: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2022-12-22 19:12:51.189932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-12-22 19:12:51.191439: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f0110f6bdd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-22 19:12:51.191454: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti Laptop GPU, Compute Capability 8.6\n",
      "2022-12-22 19:12:51.194524: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-22 19:12:51.207364: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:56] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.2\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2022-12-22 19:12:51.271828: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 11s 4ms/step - loss: 0.5850 - accuracy: 0.7857\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3908 - accuracy: 0.8560\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3337 - accuracy: 0.8773\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3004 - accuracy: 0.8892\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2733 - accuracy: 0.8987\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2515 - accuracy: 0.9072\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2341 - accuracy: 0.9137\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2177 - accuracy: 0.9183\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2032 - accuracy: 0.9243\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1917 - accuracy: 0.9276\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1812 - accuracy: 0.9326\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1687 - accuracy: 0.9370\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1586 - accuracy: 0.9394\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1534 - accuracy: 0.9419\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1434 - accuracy: 0.9463\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1352 - accuracy: 0.9485\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1298 - accuracy: 0.9506\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1231 - accuracy: 0.9536\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1163 - accuracy: 0.9550\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1129 - accuracy: 0.9573\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1068 - accuracy: 0.9595\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1020 - accuracy: 0.9603\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0997 - accuracy: 0.9617\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0922 - accuracy: 0.9655\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0916 - accuracy: 0.9652\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0843 - accuracy: 0.9684\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0835 - accuracy: 0.9689\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0804 - accuracy: 0.9692\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0789 - accuracy: 0.9701\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0771 - accuracy: 0.9711\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0747 - accuracy: 0.9723\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0735 - accuracy: 0.9725\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0656 - accuracy: 0.9748\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0703 - accuracy: 0.9743\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0644 - accuracy: 0.9762\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0686 - accuracy: 0.9747\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0621 - accuracy: 0.9772\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0679 - accuracy: 0.9755\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0575 - accuracy: 0.9785\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0586 - accuracy: 0.9774\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0608 - accuracy: 0.9772\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0547 - accuracy: 0.9797\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0570 - accuracy: 0.9791\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0553 - accuracy: 0.9797\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0551 - accuracy: 0.9797\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0492 - accuracy: 0.9812\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0540 - accuracy: 0.9798\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0470 - accuracy: 0.9831\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0490 - accuracy: 0.9816\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0474 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05633afdf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo a arquitetura da CNN\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu')) ##\n",
    "model.add(keras.layers.MaxPooling2D((2, 2))) ##\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d5c05",
   "metadata": {},
   "source": [
    "### c) Escolher uma métrica para avaliação do modelo obtido em b) no conjunto de teste, apresentando e discutindo o resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a7dd6",
   "metadata": {},
   "source": [
    "Uma métrica comum para avaliar o desempenho de um modelo de classificação é a acurácia, que mede a porcentagem de previsões corretas do modelo. Pode-se calcular a acurácia do seu modelo no conjunto de teste da seguinte maneira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ceeab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7857 - accuracy: 0.8910\n",
      "Acuracia do teste: 0.890999972820282\n"
     ]
    }
   ],
   "source": [
    "# Avaliando o modelo no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Acuracia do teste:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04738cca",
   "metadata": {},
   "source": [
    "A acurácia é uma métrica comum para avaliar o desempenho de um modelo de classificação e é definida como a porcentagem de previsões corretas do modelo. Portanto, uma acurácia de 89% significa que o modelo conseguiu prever corretamente 89% das classes das imagens do conjunto de teste.\n",
    "\n",
    "É importante lembrar que a acurácia por si só pode não ser uma medida suficientemente boa do desempenho do modelo, pois ela não leva em consideração o desbalanceamento de classes. Por exemplo, se o conjunto de dados tiver 90% de imagens de uma classe e 10% de imagens de outra classe, um modelo que sempre preveja a classe mais prevalente terá uma acurácia de 90%, mas isso não significa que o modelo esteja realmente aprendendo a distinguir as duas classes. Nesses casos, é importante avaliar o modelo usando outras métricas, como a matriz de confusão abaixo, que mostra que na diagonal principal os volumes de acertos realmente apontam para um bom desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29372dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "Matriz de Confusao\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[854,   1,  29,  21,   6,   1,  82,   0,   6,   0],\n",
       "       [  5, 973,   3,  12,   3,   0,   2,   0,   2,   0],\n",
       "       [ 22,   1, 830,   6,  85,   1,  52,   0,   3,   0],\n",
       "       [ 21,   8,  23, 896,  25,   1,  19,   0,   5,   2],\n",
       "       [  6,   1,  49,  33, 859,   0,  49,   0,   3,   0],\n",
       "       [  1,   0,   0,   0,   0, 982,   1,   7,   0,   9],\n",
       "       [126,   0,  78,  31, 119,   1, 633,   0,  12,   0],\n",
       "       [  0,   0,   0,   0,   0,  21,   0, 953,   2,  24],\n",
       "       [  8,   0,   4,   2,   3,   5,   6,   2, 970,   0],\n",
       "       [  1,   0,   0,   0,   0,   7,   1,  31,   0, 960]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_test = np.argmax(y_test, axis=-1)\n",
    "\n",
    "print('Matriz de Confusao')\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cc9f4",
   "metadata": {},
   "source": [
    "### d) Reduzir as entradas (imagens) por Encoder, identificando os hiperpâmetros utilizados no treinamento da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca376e5",
   "metadata": {},
   "source": [
    "Um encoder é uma parte de uma rede neural que é usada para codificar os dados de entrada em uma representação de menor dimensionalidade, geralmente com o objetivo de reduzir a complexidade dos dados ou para facilitar a generalização do modelo.\n",
    "\n",
    "\n",
    "1 - Definir a arquitetura do encoder. Isso inclui escolher o número de camadas, o número de filtros em cada camada, o tamanho dos filtros e a função de ativação a ser usada. \n",
    "\n",
    "2 - Compilar o encoder. Escolher uma função de perda, um otimizador e uma métrica para avaliar o desempenho do encoder.\n",
    "\n",
    "3 - Treinar o encoder. Fornecer os conjuntos de treinamento e validação ao encoder e especificar o número de épocas e o tamanho do lote. \n",
    "\n",
    "4 - Usar o encoder para codificar as imagens de entrada. Isso pode ser feito usando o método predict do encoder e passando as imagens como entrada, resultando em uma representação codificada de menor dimensionalidade das imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1a74f2",
   "metadata": {},
   "source": [
    "### e) Obter um modelo de classificação por meio de uma Rede Neural de Múltiplas Camadas – MLP, identificando os hiperpâmetros utilizados no treinamento da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107c259",
   "metadata": {},
   "source": [
    "1 - Definir a arquitetura da sua MLP. Isso inclui escolher o número de camadas, o número de neurônios em cada camada e a função de ativação a ser usada. \n",
    "\n",
    "2 - Conectar a saída do encoder à entrada da sua MLP. Isso pode ser feito usando o método add da classe Sequential do TensorFlow e passando a saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ee2d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4935 - accuracy: 0.8200\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3229 - accuracy: 0.8828\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2787 - accuracy: 0.8981\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2457 - accuracy: 0.9091\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2231 - accuracy: 0.9166\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2043 - accuracy: 0.9241\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1864 - accuracy: 0.9305\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1708 - accuracy: 0.9370\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1571 - accuracy: 0.9418\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1451 - accuracy: 0.9460\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1339 - accuracy: 0.9495\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1224 - accuracy: 0.9547\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1147 - accuracy: 0.9566\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1068 - accuracy: 0.9601\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0988 - accuracy: 0.9631\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0908 - accuracy: 0.9665\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0864 - accuracy: 0.9667\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0812 - accuracy: 0.9699\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0734 - accuracy: 0.9726\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0713 - accuracy: 0.9730\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0653 - accuracy: 0.9761\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0654 - accuracy: 0.9759\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0594 - accuracy: 0.9779\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0578 - accuracy: 0.9784\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0551 - accuracy: 0.9793\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0523 - accuracy: 0.9804\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0473 - accuracy: 0.9825\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0486 - accuracy: 0.9817\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0475 - accuracy: 0.9822\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0451 - accuracy: 0.9832\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0420 - accuracy: 0.9848\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0432 - accuracy: 0.9840\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0405 - accuracy: 0.9855\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0379 - accuracy: 0.9862\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0408 - accuracy: 0.9855\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0363 - accuracy: 0.9866\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0410 - accuracy: 0.9851\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0342 - accuracy: 0.9876\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0338 - accuracy: 0.9875\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0329 - accuracy: 0.9883\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0338 - accuracy: 0.9882\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0302 - accuracy: 0.9888\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0340 - accuracy: 0.9884\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0290 - accuracy: 0.9895\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0314 - accuracy: 0.9892\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0318 - accuracy: 0.9891\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0280 - accuracy: 0.9901\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0290 - accuracy: 0.9899\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0251 - accuracy: 0.9909\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0288 - accuracy: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0424a37520>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refazer para nao travar a memoria da GPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "\n",
    "# Arquitetura do Encoder\n",
    "encoder_input = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Conv2D(32, (3, 3), activation='relu')(encoder_input)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "encoder_output = keras.layers.Flatten()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output)\n",
    "\n",
    "# Arquitetura do MLP\n",
    "mlp_input = keras.Input(shape=(encoder.output_shape[1],))\n",
    "x = keras.layers.Dense(64, activation='relu')(mlp_input)\n",
    "x = keras.layers.Dense(32, activation='relu')(x)\n",
    "mlp_output = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "mlp = keras.Model(mlp_input, mlp_output)\n",
    "\n",
    "# Juntando o Encoder e o MLP\n",
    "model = keras.Model(encoder_input, mlp(encoder_output))\n",
    "\n",
    "# Compilando\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinando\n",
    "model.fit(x_train, y_train, epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4913cc",
   "metadata": {},
   "source": [
    "### f) Utilizar a mesma métrica de c) para avaliação do modelo obtido em e) no conjunto de teste, apresentando e discutindo o resultado, comparando-o ao obtido em c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6ff9eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7093 - accuracy: 0.9077\n",
      "Acuracia do teste: 0.9077000021934509\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Acuracia do teste:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3df4af",
   "metadata": {},
   "source": [
    "A acuracia de 90%, praticamente igual ao resultado observado na rede neural convolucional.\n",
    "Comparando a matriz de confusao das duas tecnicas, pode-se observar que ambas apresentaram valores baixos apenas para a setima coluna, sendo:\n",
    "63% para a CNN\n",
    "74% para o MLP + Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2002772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "Matriz de Confusao\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[843,   1,  25,  10,   7,   1, 110,   0,   3,   0],\n",
       "       [  0, 984,   2,   7,   3,   0,   2,   0,   2,   0],\n",
       "       [ 19,   0, 850,  10,  64,   2,  55,   0,   0,   0],\n",
       "       [ 21,   8,   7, 891,  36,   2,  33,   0,   2,   0],\n",
       "       [  2,   0,  35,  21, 886,   0,  54,   0,   1,   1],\n",
       "       [  0,   0,   0,   0,   0, 981,   0,  13,   0,   6],\n",
       "       [ 88,   1,  67,  27,  64,   1, 745,   0,   7,   0],\n",
       "       [  0,   1,   0,   0,   0,  14,   0, 959,   0,  26],\n",
       "       [  6,   0,   5,   3,   4,   2,   2,   2, 975,   1],\n",
       "       [  0,   0,   1,   0,   0,   6,   0,  30,   0, 963]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_test = np.argmax(y_test, axis=-1)\n",
    "\n",
    "print('Matriz de Confusao')\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
